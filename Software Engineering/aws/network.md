# Network

## Elastic Network Interface

A logical component in VPC that represets a virtual network card. It allows

- 1 primary IPv4, 1 or more secondary IPv4
- 1 elastic IP per private IP
- 1 public IPv4 address
- 1 or more IPv6 address
- 1 or more security groups
- provide mac address
- bound to AZ

```
eth0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500 (primary ENI)
    some IPv4 address
eth1: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500 (secondary ENI)
    some IPv4 address
```

> note above is not accurate and only meant for giving an example

ENI can be create independently and connected to instance on the fly. It can be
used as network failover. Manual created ENI persist when instance is
terminated. Multiple ENI on single EC2 is possible.

## Elastic Load Balancer (ELB)

A load balancer acts as a single point of access through static DNS  and
forwards traffic to instances to spread load, have seamless failure handling of
downstream instance. ELB is able to do health check, ssl termination, enforce
stickiness with cookies. It is high available across AZ and separates public
traffic from private traffic. ELB is managed by AWS with few tuning knobs.
Upgrades, maintenence are all done behind the scene. ELB integrates well with
other AWS services. ELB healthcheck is done by checking on a port and route to
decide if traffic is forwarded.

- CLB: HTTP, HTTPS, TCP, TLS/SSL (secured TCP)
- ALB: HTTP, HTTPS, websocket
- NLB: TCP, TLS, UDP
- GWLB: operates at OSI L3 IP protocol

EC2's security group should be used as ELB's security group such that ELB's
accepts all EC2's incoming traffic.

### Application Load Balancer (ALB)

Is a L7 load balancer that supports,

- HTTP across multiple machines (target group) or multiple application in same machine/containers
  - route to different target groups by configuring listener rule
    - based on url path
    - based on hostname in path
    - based on query string/headers
- HTTP/2 and websocket
- redirects (HTTP to HTTPS) and integrates with AWS certificate manager
- high availablity with minimum 2 AZ setup
- microservices and container based application
- port mapping to dynamic route (ECS?????)
- route to multiple target group
- health checks at target group level
- gets fixed hostname
- application sees true client IP in header `x-forwarded-for`
  - including port with `x-forwarded-for-port` and proto `x-forwarded-proto`

Target group can be EC2 (optionally managed by ASG), ECS tasks, lambda
function (tranlated to JSON event), IP address (must be private e.g. on prem
servers).

It is recommended to only allow instance in target group to accept inbound
traffic from loab balancer.

### Network Load Balancer (NLB)

A L4 load balancer that support TCP and UDP load balancing.

- extreme high performance: at million request per second
- low latency ~100ms (vs ALB ~400ms)
- have static IP per AZ and support elastic IP assignment
  - good for whitelisting specific IP
  - limit application exposure to limited IPs
- minimum 1 AZ
- health check only for TCP and HTTP(s)

Target group can be EC2, IP address (private), ALB.

### Gateway Load Balancer (GWLB)

Deploy, scale and manage fleet of 3rd party network virtual applicance in AWS.
Basically directing traffic to firewall/intrusion detection and prevention
system/deep packet inspection/payload manipulation at L3 network level with
network packages. It is transparent to incoming traffic and acts as single
entry/exit point. It can load balance the traffic to the appliances. It uses
GENEVE protocol on 6081 port. Possibile to drop packages.

![gwlb](gwlb.PNG)

Target group can be EC2 instances or IP address (private).

### Sticky Sessions/Session Affinity

ELB allows client to always connect to same instance behind load balancer (
only ALB/NLB) using coockie and expiry control at a cost of potential
unbalanced load.

- applicaiton based cookie
  - custom cookie generated by application
    - can specify any custom attribute required by applicaiton
    - cookie name must be unique for each target group and not `AWSALB*`
  - application cookie generated by load balancer
    - uses `AWSALBAPP` as cookie name
- duration based cookie
  - generated by LB with name `AWSALB`

Is setup by enabling settings under `attribute` tab.

### Cross Zone Load Balancing

For ALB it is enabled by default (disable at target group) and is free of
charges for inter AZ data.

For NLB and GWLB is default disabled and is chargeable for inter AZ data. To
enable for NLB and GWLB at `attribute` tab.

## SSL/TLS

> check [network ssl](../../Network/Interview%20Question.md#3.-explain-TLS-handshakes-(SSL)).

When using TLS on ELB, a HTTPS listener must be setup with appropriate
certificates from ACM/IAM/import (X.509). Default to have one and optional a
list of certification for multi domain support. Client can use server name
indication (SNI) to specify hostname. It is also possible to support older
versions of TLS/SSL using a security policy.

### Server Name Indication

Address the problem of loading multiple SSL certificates to on server to serve
multiple sites (multiple listeners). The client specify the host name and
server finds the appropriate certificate or fallback to default. Only ALB, NLB
and CloudFront supports it.

## Connection Draining (CLB) and Deregistration Delay (ALB/NLB)

Time to complete in-flight requets while the instance is de-regestering or
unhealthy i.e. stop sending new request to EC2. Can be set as 0~3600 seconds.

## Route 53

[DNS ref](../../Network/Interview%20Question.md##-16.-DNS)

> 53 is the traditional DNS port

High available, scalable fully managed authoritative DNS. One of AWS global
service and only service that guarantees 100% SLA. Provides domain registrar
service.

Route 53 records stores information on how to route traffic to domain and
contains,

- domain/subdomain name
- record type
- value
- routing policy i.e. how R53 respond to queries
- TTL (record cached at DNS resolvers)
  - mandatory except for alias records which is set by AWS R53

### R53 Hosted Zone

R53 NS records store name server for hosted zones.

Container for records that define traffic routing to a domain and subdomains.
R53 support public and private hosted zone.

- public hosted zone
  - contains records that specify traffic routing on public internet
- private hosted zone
  - specify traffic routing within one or more VPC (private domain names)

### CNAME vs alias

R53 cannot create CNAME record for top node of DNS namespace (zone apex) e.g.
can not create for `example.com` but possible for `www.example.com`. AWS
resources are exposed as hostname e.g.
`ip-1-31-25-2.ap-southeast-1.compute.amazonaws.com`. CNAME only maps non-root
domain to another thus it can not be mapped to `example.com`. However alias
can map any hostname to AWS resource (root or non-root). R53 provides this for
free and having a native health check.

R53 alias record is an extention to the DNS functionality. When tied to ALB, if
the IP address changes, it will be recognized (?). It can be used for top node
of DNS namespace (zone apex). alias record is always A/AAAA record for AWS
resource.

Common AWS resource using R53

- ELB
- CloudFront distribution
- Api geteway
- S3 websites
- BeanStalk
- Global Accelerator
- VPC endpoints
- R53 record in the same hosted zone

> note alias record cannot be set for ec2 DNS

### Health Checks

Health checks are done mainly for public resources i.e. AWS ping from internet.
These health checks are for automated DNS failover by,

- monitoring the endpoint (application, server, other AWS resource)
- calculated health checks (other health checks)
- health check on CloudWatch Alarm (helpful for private resources)

Endpoint monitoring is from ~15 global health checkers at interval of 30 sec
(or higher with higher cost) and supports HTTP(S)/TCP. If > 18% deems healthy,
it is considered healthy. If the payload is too huge, only first 5120 byte data
is used for content check. Must be enabled.

Calculated health check combine multiple health check into one with `AND`, `OR`
and `NOT` logic up to 256 health check. Possible to setup % pass for overall
pass.

CloudWatch Alarm option is done through setting CloudWatch Metric associated
with CloudWatch Alarm and then create a health check that checks on the alarm
itself.

### Routing Policy

> note that routing means how R53 response to queries but no actual routing

Simple routing routes to single resource. If multiple values are specified, all
will be returned and client will choose one. When alias is enabled, only one
AWS resouce can be specified as target. This can not be associated to health
check.

Weighted allows to set a percentage to each resource with single 0 as disable
and all 0 implying equal weight. Health checks are possible and weight can be
updated dynamically for load balancing or A/B testing. The records must be of
same record name name and record type.

Latency allows to route resource with lowest latency based on latency between
user and AWS region. Support health checks and failover. The records must be of
same record name name and record type.

Failover is similar to the above ones, same record name and type associated
to health check. The difference is that it is meant for active-passive
failover. Unless the primary is unhealthy, all traffic will always be routed to
primary.

Geolocation is based on user location i.e. by continent, country etc. (if there
is an overlap then use the most precise option). Requires a default and
supports health check.

Geoproximity route based on the resource and user location. Can shift traffic 
to resouce based on bias i.e. AWS region or longitude/lattitude for on prem.
Positie bias value routes more traffic to resource; Negative bias value route
less traffic to resource. R53 traffic flow must be enabled to use this feature.

IP route policy is based on client ip by providing a list of CIDR of clients
and the corresponding endpoint. This targets to optimize performance and reduce
network cost i.e. route end user of certain ISP to a specific endpoint.

Multi-value route policy is for routing traffic to multiple resources by
returning multiple values that can be associated with health checks (only
returns health resources). Up to 8 healthy records is returned and is not an
substitude for ELB. The records must be of same record name name and record
type.

AWS allows user to use R53 or other DNS record management service for 3rd party
domain name. If domain is bought on 3rd party registrar and intend to use R53
as DNS service provider. Create a hosted zone in R53 and update NS records on
3rd party website to use R53 name servers.

## CloudFront (CDN)

CloudFront is primarily used as a cache for web content at edge (AWS point of
prescence) to improve read performance. CloudFront also provides DDoS
protection, AWS Shield and Web FireWall (WAF) integration. There are two
possible origins,

- S3
  - provides enhanced security through Origin Access Control for ingress to S3 (uploads)
  - provides TTL + cache + AWS POPs
  - (vs S3 CRR) does not require setup for each region and not limited to read only capability
- custom HTTP
  - ALB/EC2/S3 website
  - ALB/EC2 needs to be public for CloudFront as it has no VPC capability
  - ALB/EC2 security group must allow all edge POPs to access

Geo restriction is possible with CloudFront to have a allow/block list of
countries to serve content. Countries are determined by 3rd party geo IP
database. Usually geo restriction is meant for copyright laws compliance.

CloudFront cache invalidation by default will only update the content when TTL
expires, however it is possible to force a full or partial (i.e. special path)
cache refresh with CloudFront invalidation.

### Pricing Model

Cost per edge location varies i.e. some locations are cheaper than others.
Reducing number of edge locations helps to optimize cost.

- price class All: best performance
- price class 200: most location covered excluding the most expensive regions
- price class 100: only least expensive regions

## AWS Global Accelerator

Addressed situation where application is deployed in a single region but would
like to be accessed globally. If users accessed through public internet, it
will cause significant latency as it takes many hops to reach the VPC. This is
done through using Anycast IP.

- unicast IP: one server holds one IP address
- anycast IP: all server hold same IP address and client is routed to nearest one

AWS global accelerator creates 2 Anycast IP for the application and leverages
on AWS internal network (from edge location) to route to the assigned endpoint.

![glb xlrt](glb-xlrt.PNG)

AWS global accelerator has consistent performance by having lowest latency
routing and fast regional failover. It works with client cache as the 2 anycast
IP does not change. It terminates connection from client at edge location and
establish new connection with the endpoints for faster response time and
latency.

AWS global accelerator does health checks and redirect traffic to another
available endpoint in the endpoint group when the active endpoint is determined
unhealthy.

AWS global accelerator works with the endpoints below

- elastic IP
- EC2
- ALB/NLB
- public/private

### VS CloudFront

| feature | CloudFront | Global Accelerator |
|-|-|-|
| AWS global network and edge location | Y | Y |
| AWS Shield for DDoS protection | Y | Y |
| cache content performance improve | Y | N |
| dynamic content (API acceleration/dynamic site delivery) performance improve | Y | N |
| serve content at edge | Y | N |
| improve performance over TCP/UDP | N | Y |
| proxy packet at edge to one or more AWS region | N | Y |
| gaming (UDP)/IOT (MQTT)/VOIP | N | Y |
| HTTP use cases that requires static IP | N | Y |

## API Gateway

A few options that can expose a lambda function to client

- expose directly which clients would need IAM permissions
- fronted by an ALB and expose it as a HTTP endpoint
- fronted by API gateway and use it as an proxy to lambda (more than HTTP endpoint)

> take note of the default API gateway timeout is independent of lambda's

API gateway is a serverless option to create public accesssible REST api at
regional level. A list of features including

- WebSocker support
- API versioning support
- multiple environment support
- security (authentication and authorization)
- API keys creation
- request throttling
- import/export Swagger/Open API to define API
- transform and validate request and responses
- generate SDK and API spec
- caching

API gateway is flexible and allows exposing HTTP endpoints and any AWS service
besides lambda function. With the features provided out of the box, it is
easier to manage an API with API gateway.

### Endpoint Types

- edge optimized (default) for global clients
  - request are routed through CloudFront Edge location however, API gateway is in one region
- regional
  - for clients within same region
  - can manually combine with CloudFront (more control over CloudFront cache etc.)
- private
  - access only from VPC using ENI
  - use resource policy to define access

### Security

Users can be authenticated through IAM roles (internal applications), AWS
Cognito (for external users) or custom authorizer (own logic in lambda).

Custom domain name HTTPS is integrated with AWS Certificate Manager,

- edge optimized must have certificate in `us-east-1` (same as CloudFront)
- regional endpoint must have certificate in the same region as API gateway

and CNAME or A-alias record must be setup in R53.

## Virtual Private Network

![vpc](vpc.PNG)

> Provides isolation at network level

All AWS accounts has a default VPC and new EC2 instances are launched to the
deafult VPC is no subnet is specified. The default VPC has internet
connectivity and instances within it has public IPv4 address. Public and
private IPv4 DNS names are also provided. Default VPC

- `172.31.0.0/16`
- no flow logs enabled
- a main route table and network ACL is associated
  - in the route table thre are two destination routes
    - `172.31.0.0/16` to target `local`
    - `0.0.0.0/0` to target `igw-someInternetGateway` which gives internet access

> Public IPv4 address are auto assigned only if subnet settings are setup as so

Route tables has explicit and non explicit associations. Non explicitly
associated route tables' subnets are associated to the main route table. It is
usually preferable to have route tables explicitly associated to subnet.

### AWS VPC

5 VPC per region (soft limit), 5 CIDR per VPC and each CIDR can have minimum
(/28, 16 IP addresses) and maximum (/16, 65536 IP addresses). A general rule
to assign CIDR is to not overlap with the other communicating networks.

> the Tenancy option when creating VPC is for cases where dedicated hardware is
> required.

### AWS Subnets

Subnets are just a subrange of IPv4 address within VPC. New subnets unless
specified are associated to the default VPC i.e. grabs a share $2^{12}$ of the
$2^{16}$ IPs. These subnets are in some availability zone within the VPC
region. $5$ IPs are reserved, namely the first 4 and last 1.

- `0` will be the network address
- `1` is reserved for VPC router
- `2` is reserved for AWS mapping to Amazon provided DNS
- `3` is reserved for future uses
- `255` Network Broadcast Address, despite AWS does not support broadcast

AZ is defined at subnet level. In general subnet's IPv4 CIDR block should be
limited for ELBs and front facing infrastructures. Each subnets has its route
table and network ACL. Network ACL has inbound and outbound rules.

At subnet creation level, there is still yet a clear distinct difference
between public and private VPC (yet). They should have no internet access.

### Route Table

To route from subnets to IGW, VPC Peering Connections, VPC Endpoints and etc.
An example

| no | destination | target |
|-|-|-|
| 1 | 0.0.0.0 | igw |
| 2 | 10.0.0.0/16 | local |
| 3 | 172.31.0.0/16 | pcx-123 |
| 4 | ::/0 | eigw-123 |

1. implies enablement of internet access through IGW.
2. implies IPv4 traffic routed within VPC (10.0.0.0/16) is covered by local route.
3. implies IPv6 traffic within VPC is covered by peer connection.
4. implies IPv6 internet traffic goes through `eigw`.

### AWS Internet Gateway (IGW)

A service that scales horizontally, highly available and redundant which allows 
resources in VPC to connect to internet however, on their own still dont allow
internet access. Route table must be edited to make it work. It must be created 
separately from VPC. Only one VPC can be attached to one IGW and vice versa.
The creation of IGW is straightforward by specify its name and attach to VPC.

### Internet connectivity

1. Internet gateway -> VPC
2. VPC -> Subnet
3. Subnet -> Route Table
4. Route Table Routes's source/destination setting to set `0.0.0.0` and `IGW`

### Bastion Hosts

A (Deprecated) approach to connect to a EC2 instance on private subnet through
an EC2 instance called bastion host within the public subnet of the same VPC.
The private EC2 instance must allow the bastion host security group or the
private IP of the bastion host.

> ssh is done by specifying the private IP address of the EC2 instance in
> private subnet

### NAT Instance (deprecated, examinable)

Network Address Translation instance that allows EC2 instances in private
subnets to connect to internet. It is launched in the public subnet, EC2
source/destination check must be disabled and must have an Elastic IP attached
to it. Lastly Route Table must be configured to route traffic from private
subnet to NAT instance. NAT instance comes as an Amazon Linux AMI that has
reached EOL, not HA or resilient, has limited traffic bandwidth (depends on EC2
size) and security groups/inbound/outbound rules has to be manually managed.
Security group for NAT instance should at least allow inbound HTTP(s) from
private subnet CIDR and internet access outbound rules.

![nat inst](nat-inst.PNG)

> source destination check is disabled as they are modified over the request
> cycle

### NAT Gateway

AWS managed NAT with higher bandwidth, HA and without administration (sg). It
charges based on hour usage and bandwidth used. NATGW is created in a specific
AZ with Elastic IP. It cant be used by EC2 in the same subnet and required IGW
(private subnet => NATGW => IGW).

> 5 Gbps bandwidth that scales up to 100 Gbps

NATGW is resilient within single AZ, and multiple NATGW is needed for fault
tolerance. There is no cross AZ failover as AZ goes down so does NAT.

### NACL and Security Groups

NACLs are stateless while security groups are stateful i.e. any inbound traffic
from SG is not evaluated during outbound but NACL is evaluated twice. NACL are
firewall which controls traffic from and to subnets. There is one NACL per
subnet and new subnet are assigned to default NACL. NACL rules are defined

- with a precedence number, higher precedence with lower number
- first rule match will drive decision
- the last rule is an `*` that denies the request if there is no match
- it is recommended to add rules in increments of 100
- newly created NACL denies everything
- default NACL accepts everything
- a good way to block IP at subnet level

#### Emphemeral Ports

For any two endpoints to establish a connection, ports must be used. Clients
connects to a defined port and expects response on an ephemeral port. Different
OS has different port ranges,

- IANA & Windows -> 49152 - 65535
- Linux -> 32768 - 60999

![srv comm](srv-comm.PNG)

With emphemeral ports existence, NACL has to be designed that it allows
appropriate inbound and outbound rules. It can get hairy when multiple subnets
are involved in the communication.

![emp nacl](emp-nacl.PNG)

#### NACL vs Security Groups

| SG | NACL |
|-|-|
| instance level | subnet level |
| stateful: return traffic is always allowed | stateless: requires inbound/outbound to be explicit |
| all rules to be evaluated before decision | first rules from smaller number match drive decision |
| applies to EC2 when specified | automatically applies to all EC2 in subnet |

### VPC Peering

> traffic cost?

Privately connect two VPC using AWS network such that they behave as if they
are in the same network. The two VPCs should not have overlapping CIDR and
VPC Peering connections are not transitive i.e. A <-> B, B <-> C does not
imply A <-> C. Route Tables in each VPC subnet must also be updated to ensure
EC2 instances can communicate with each other. VPC Peering connection can be
between VPCs in different AWS accounts and/or regions. Security group in a
peered VPC can be referenced between same region cross account.

### VPC Endpoints

Without VPC endpoints, public accessible services e.g. DDB, S3 and CloudWatch
are routed out from VCP through public internet before reaching the services.
Every AWS service is publicaly exposed with a public url, VPC endpoints powered
by AWS PrivateLink helps to connect them using AWS private network. These VPC
Endpoints are redundant, scales horizontally and removes the need of IGW,
NATGW, and etc to AWS services.

> in case it does not work check DNS setting resolution in VPC and route tables

- interface endpoints (powered by PrivateLink)
  - provisions an ENI as an entry point (must attach SG)
  - supports most AWS services
  - cost per hour and per GB data processed
- gateway endpoints
  - must be used as a target in the route table and does not uses SG
  - only for S3 and DDB
  - it is free

For S3 and DDB unless there is a need to access from on-prem (site to site VPN
or Direct Connect), a different VPC or different region, gateway endpoints is
always the option to choose.

![vpc endpoints](vpc-endpoints.PNG)

> when using CLI to do a `aws s3 ls` it might not return results despite
> correct setup of endpoint as CLI's default region is `us-east-1`.

### AWS Privatelink

Provides private connectivity between VPC, supported AWS services and on-prem
network without exposing traffic to public internet. No Internet GateWay, NAT
device, public IP address, AWS DX connection or S2S VPN needed to allow
communication with the service from private subnets.

### VPC FLow Logs

Log that capture information about IP traffic going into interfaces including

- VPC flow logs
- subnet flow logs
- ENI flow logs

to help monitor and troubleshoot connectivity issues. Flow logs data can go to
S3, CloudWatch Logs and KDF. It also captures network information from AWS
managed interfaces,

- ELB
- RDS
- ElastiCache
- Redshift
- WorkSpaces
- NATGW
- Transit Gateway and etc.

![flow log syntax](flow-log-syntax.PNG)

Analysis can be done through S3+Athena or using CloudWatch Logs Insights.

### Site-to-site VPN

To establish a private site to site VPN conenction using a customer gateway and
a VPN gateway.

- Virtual Private Gateway
  - VPN concentrator on AWS side
  - created and attached to the VPC for the S2S VPN connection
  - possibility to customize Autonomous System Number
  - **route propagation in route table associated with subnets must be enabled**
- Customer Gateway
  - software application or physical hardware on customer side
  - use public internet routable IP address for customer gatway device
  - if it is behind a NAT device with NAT-traversal then the public IP of NAT

![s2s setup](s2s-setup.PNG)

#### AWS VPN CloudHub

Provides secure communication between multiple sites if there are multiple VPN
connection. It is a low cost hub and spoke model for primary or secondary
network connectivity between different location through VPN. Note the VPN
connection goes through the public internet (encrypted). To set it up, connect
multiple VPN to single Virtual Private Gateway, setup dynamic routing and
configure route tables.

![cloud hub](cloud-hub.PNG)

### Direct Connect (DX)

Provides a dedicated **private** connection from remote network to VPC.
Dedicated connection is setup between customer DX and AWS DX location together
with VPC's Virtual Private Gateway. With this, public and private resource can
be connected on same connection (through virtual interface). Support IPv4 and
6.

> data in transit is private, not encrypted; AWS DX + VPN provide IPsec
> encrypted private connection

- increased bandwidth throughput -> lower cost
- more consistent network experience
- support hybrid environment (on prem + cloud)

![dx-1](dx-1.PNG)

If DX need to connect to more than one VPC in multiple region (same account), a
DX Gateway is needed.

![dx-gw](dx-gw.PNG)

Connection types

- dedicated connection: 1, 10, 100 Gbps capacity
  - dedicated physical ethernet port
  - make request to AWS and completed by AWS DX partner
- hosted connection: 50, 500 Mbps to 10 Gbps
  - request to DX partners
  - capacity can be added or removed on demand

> lead time are often more than 1 month

![dx resilient](dx-resilient.PNG)

### Transit Gatwway

Network topology can gets complicated as the scale grow. Transit Gateway
provides transitive peering between VPCs and on-prem through a hub and spoke
(star) connection. It is a regional resource that works cross region and can
share cross account using Resources Access Manager (RAM). Route Table limits
which VPC can communicate to another. It works with DX, VPN connection and
VPCs. It is the only service AWS provides that supports IP multicast.

![tgw](tgw.PNG)

#### S2S VPN ECMP

Equal cost multipath routing is a routing strategy to allow forwarding a packet
over multiple best path. To create multiple S2S VPN connection to increase
bandwidth of AWS connection.

![ecmp](ecmp.PNG)

Each VPN has 2 tunnels, when connected directly to a virtual private gateway,
one tunnel is used. Compared to ECMP both tunnels are used and doubled the
bandwidth (with increased cost). More VPN connection can be added to further
improve the bandwidth.

### VPC Traffic Mirroring

Capture and inspect network traffic in VPC without distrupting applications by
mirroring and routing the traffic to security appliances. Traffic are mirrored
from ENI to ENI or NLB to capture all packets (optional filtering). Source and
target can be in different VPC with VPC Peering.

![traf mir](traf-mir.PNG)

### IPv6

IPv4 is designed for 4.3B addresses and will be exhausted soon. IPv6 is
designed for $3.4e38$ addresses. They are all public and internet routable. It
is in the format of `x.x.x.x.x.x.x.x` with each `x` is a hexadecimal that
ranges from `0000` to `ffff`. Although IPv4 can not be disabled in VPC but IPv6
can. When enabled, instances are operating in a dual-stack mode i.e. at least a
private IPv4 and a public IPv6.

Times when EC2 instances can not be launched it is usually running out of IPv4
addresses as it almost impossible to fail to acquire IPv6 address. Resolve this
by creating a new IPv4 CIDR in the subnet.

> IGW supports IPv6

#### Egress only Internet Gateway

Only for IPv6 to allow instance in VPC outbound over IPv6 while preventing the
internet to initiate IPv6 connection to instances. Route Tables must be
updated.

![ipv6 route](ipv6-route.PNG)

## Networking Cost in AWS

> its simplified

![ec2 nw cost](ec2-nw-cost.PNG)

Key takeaway: use private IP as much as possible (cheap and performant); JA and
cost does not go together; egress cost (out from AWS) is costly, minimize data
out (filtering, aggregation) before sending out to on-prem for hybrid; DX
location must be same AWS region to minimize egress cost;

![s3 nw cost](s3-nw-cost.PNG)

Key takeaway: CF to internet is slightly cheaper and reduce costs associated
with S3 request pricing (7x); CF provides caching (low latency)

![nat vpc gw](nat-vpc-gw.PNG)

## Network Protection

- NACL
- SG
- WAF
- Shield & Shield Advanced
- AWS Firewall Manager

To protect network at VPC level, use AWS Network Firewall. AWS Network Firewall
provides L3-L7 protection. All traffic in any direction are inspected.
Underlying is using AWS GWLB. Rules are centrally managed cross account with
AWS Firewall Manager to many VPCs. Thousands of rules supproted
(IP/port/protocol/domain/regex matching). Traffic filtering with allow, drop,
alert for traffic matches the fules. Active flow inspection to protect against
network threats with intrusion prevention capabilities (AWS managed). Logs can
be sent to S3, KDF and CloudWatch Logs.

![nw fw](nw-fw.PNG)